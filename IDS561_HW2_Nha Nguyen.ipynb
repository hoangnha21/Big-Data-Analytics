{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a440fc02",
   "metadata": {},
   "source": [
    "# IDS 561 - Homework 2 \n",
    "# By Hoang Nha Nguyen \n",
    "# UIN: 671491808"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b751cfb",
   "metadata": {},
   "source": [
    "Setting up Pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "493cb538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in /Users/hoangnha218/opt/anaconda3/lib/python3.9/site-packages (3.3.2)\n",
      "Requirement already satisfied: py4j==0.10.9.5 in /Users/hoangnha218/opt/anaconda3/lib/python3.9/site-packages (from pyspark) (0.10.9.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install -q findspark\n",
    "!pip install pyspark\n",
    "\n",
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5089ced2",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3049cfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#Load the Amazon data\n",
    "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
    "data = spark.read.csv('Amazon_Responded_Oct05.csv',header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce55d7e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/14 14:17:42 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession                                                          # Creating a Spark Session\n",
    "#Create Spark session                                                        \n",
    "spark = SparkSession.builder.appName('xyz').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5245d03f",
   "metadata": {},
   "source": [
    "# Step 1 : Remove the records where “user_verified” is “FALSE”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09caa120",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Loading the Amazon dataset\n",
    "\n",
    "amazon = spark.read.csv(\"Amazon_Responded_Oct05.csv\", header = \"true\",inferSchema=True,encoding='UTF-8',multiLine=True,escape=\"\\\"\").select('id_str','tweet_created_at','user_verified','favorite_count','retweet_count','text_')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62050005",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "171899"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon1 = amazon.select('id_str','tweet_created_at','user_verified','favorite_count','retweet_count','text_')\n",
    "\n",
    "amazon2 = amazon1.filter(amazon1.user_verified=='True')\n",
    "\n",
    "amazon2Rdd = amazon2.rdd\n",
    "\n",
    "#Convert csv to rdd\n",
    "amazon2Rdd.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d01007",
   "metadata": {},
   "source": [
    "# Step 2 : For the remaining records (“user_verified” is “TRUE”), group by created date, and count the number of tweets for each date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c889531d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#group by date\n",
    "from datetime import datetime                                                                    \n",
    "\n",
    "import pytz\n",
    "\n",
    "def changeDate(x):\n",
    "\n",
    "  date = x.split(' ')\n",
    "  return date[1]+' '+ date[2]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5adbceb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"'793281386912354304'\",\n",
       "  'Nov 01',\n",
       "  True,\n",
       "  0,\n",
       "  0.0,\n",
       "  \"@SeanEPanjab I'm sorry, we're unable to DM you. Was this order purchased on https://t.co/nUUp5MLhYl, or one of our other sites? ^CL\"),\n",
       " (\"'793502854459879424'\",\n",
       "  'Nov 01',\n",
       "  True,\n",
       "  0,\n",
       "  0.0,\n",
       "  '@SeanEPanjab Please give us a call/chat so we can look into this order for you: https://t.co/hApLpMlfHN. ^HB'),\n",
       " (\"'793504235400884224'\",\n",
       "  'Nov 01',\n",
       "  True,\n",
       "  0,\n",
       "  0.0,\n",
       "  '@SeanEPanjab Without providing any sensitive information, do the order details indicate that the item was ever shipped? ^SW')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ChangeDate = amazon2Rdd.map(lambda x: (x[0], changeDate(x[1]),x[2],x[3],x[4],x[5]))\n",
    "\n",
    "ChangeDate.take(3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9c25b5bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------+\n",
      "|  _1|    _2|\n",
      "+----+------+\n",
      "|1536|Jan 03|\n",
      "|1508|Jan 10|\n",
      "|1496|Jan 11|\n",
      "|1410|Jan 12|\n",
      "|1364|Jan 06|\n",
      "|1360|Jan 07|\n",
      "|1342|Jan 20|\n",
      "|1298|Mar 02|\n",
      "|1295|Jan 13|\n",
      "|1292|Jan 21|\n",
      "|1290|Jan 14|\n",
      "|1286|Jan 18|\n",
      "|1279|Dec 15|\n",
      "|1259|Jan 24|\n",
      "|1249|Nov 18|\n",
      "|1201|Dec 03|\n",
      "|1196|Jan 02|\n",
      "|1192|Jun 27|\n",
      "|1190|Jul 04|\n",
      "|1175|Jan 19|\n",
      "|1163|Jan 25|\n",
      "|1149|Jan 23|\n",
      "|1143|Jan 08|\n",
      "|1124|Jan 17|\n",
      "|1120|May 11|\n",
      "|1112|Jul 03|\n",
      "|1109|Mar 30|\n",
      "|1089|Apr 05|\n",
      "|1083|Jan 26|\n",
      "|1080|Jan 27|\n",
      "+----+------+\n",
      "only showing top 30 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#number of tweets for each date\n",
    "groupRdd = ChangeDate.map(lambda x: (x[1],1)).groupByKey()                            \n",
    "\n",
    "freq = groupRdd.mapValues(sum).map(lambda x: (x[1],x[0])).sortByKey(False)\n",
    "\n",
    "freq.toDF().show(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fbb71a0",
   "metadata": {},
   "source": [
    "# Step 3 : For the date with highest number of tweets, calculate the sum of “favorite_count” and “retweet_count” for each tweet on that day. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "579dd4e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jan 03\n"
     ]
    }
   ],
   "source": [
    "datafreq = freq.toDF()\n",
    "\n",
    "maxcount = datafreq.agg({\"_1\": \"max\"}).rdd.collect()[0][0]\n",
    "\n",
    "maxdate = datafreq.filter(datafreq._1== maxcount).select(\"_2\").rdd.collect()[0][0]\n",
    "\n",
    "print(maxdate)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cd338fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then report the text content of the top 100 tweets with highest sum\n",
    "import string                                                                                                  \n",
    "\n",
    "data_ChangeDate = ChangeDate.toDF()\n",
    "\n",
    "data_sum = data_ChangeDate.filter(data_ChangeDate._2==maxdate).withColumn(\"sum_tweet\", data_ChangeDate._4+data_ChangeDate._5).sort('sum_tweet', ascending=False)\n",
    "\n",
    "data_frequencyCount = data_sum.limit(100).rdd.flatMap(lambda x: x._6.split(\" \"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "21656e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eliminate the integers, punctuations and coverting all words to lower case\n",
    "def cleandata(x):                                                                                           \n",
    "  \n",
    "  lowercase = x.lower()\n",
    "  punc = list(string.punctuation)\n",
    "  \n",
    "  for x in range(0, 9):\n",
    "    punc.append(str(x))\n",
    "  for i in punc:\n",
    "    lowercase = lowercase.replace(i,'')\n",
    "  return lowercase\n",
    "\n",
    "cleandata = data_frequencyCount.map(cleandata)\n",
    "\n",
    "# Eliminating the spaces\n",
    "cleandata = cleandata.filter(lambda x:x!='')                                                                  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ed6585",
   "metadata": {},
   "source": [
    "# using MapReduce to count word freq of 100 tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e6ee825b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('a', 24)\n",
      "('ab', 1)\n",
      "('abhinavsaroj', 4)\n",
      "('able', 3)\n",
      "('about', 4)\n",
      "('aboutasix', 1)\n",
      "('above', 2)\n",
      "('access', 3)\n",
      "('account', 2)\n",
      "('accttypically', 1)\n",
      "('add', 1)\n",
      "('address', 1)\n",
      "('adibaddy', 1)\n",
      "('advise', 1)\n",
      "('ae', 3)\n",
      "('af', 2)\n",
      "('aim', 2)\n",
      "('ak', 1)\n",
      "('alerts', 2)\n",
      "('alexa', 1)\n",
      "('alexisgraham99', 1)\n",
      "('allow', 1)\n",
      "('already', 1)\n",
      "('always', 3)\n",
      "('alyssagoldman', 3)\n",
      "('am', 1)\n",
      "('amazon', 7)\n",
      "('amazonhelp', 1)\n",
      "('amazonin', 2)\n",
      "('ambermullennn', 1)\n",
      "('amp', 1)\n",
      "('an', 7)\n",
      "('and', 17)\n",
      "('any', 8)\n",
      "('anything', 1)\n",
      "('apologies', 2)\n",
      "('app', 6)\n",
      "('application', 1)\n",
      "('appreciation', 1)\n",
      "('ar', 3)\n",
      "('are', 2)\n",
      "('arent', 1)\n",
      "('ariannadelbene', 1)\n",
      "('arrange', 1)\n",
      "('arrive', 6)\n",
      "('arrived', 3)\n",
      "('arrives', 1)\n",
      "('as', 4)\n",
      "('ask', 1)\n",
      "('asked', 1)\n",
      "('assist', 2)\n",
      "('assistance', 1)\n",
      "('at', 6)\n",
      "('athena', 1)\n",
      "('athenarivera', 1)\n",
      "('atoz', 1)\n",
      "('attention', 2)\n",
      "('availability', 1)\n",
      "('available', 2)\n",
      "('aw', 1)\n",
      "('awww', 1)\n",
      "('babajabalpuri', 4)\n",
      "('back', 1)\n",
      "('bad', 2)\n",
      "('baileyoz', 1)\n",
      "('bayou', 1)\n",
      "('bbyuniversecb', 1)\n",
      "('be', 8)\n",
      "('becoming', 1)\n",
      "('been', 2)\n",
      "('being', 1)\n",
      "('below', 1)\n",
      "('better', 3)\n",
      "('bingewatch', 1)\n",
      "('birthday', 2)\n",
      "('books', 1)\n",
      "('bringing', 2)\n",
      "('brooklynnnross', 1)\n",
      "('browser', 1)\n",
      "('business', 2)\n",
      "('but', 3)\n",
      "('bv', 2)\n",
      "('by', 8)\n",
      "('ca', 1)\n",
      "('can', 26)\n",
      "('cancel', 1)\n",
      "('cant', 2)\n",
      "('card', 2)\n",
      "('carriers', 1)\n",
      "('case', 2)\n",
      "('caused', 1)\n",
      "('cd', 1)\n",
      "('certainly', 1)\n",
      "('chadrallen', 1)\n",
      "('chat', 1)\n",
      "('check', 1)\n",
      "('checking', 1)\n",
      "('checkout', 1)\n",
      "('chunkkyyy', 2)\n",
      "('cj', 2)\n",
      "('cl', 2)\n",
      "('claim', 1)\n",
      "('cleared', 1)\n",
      "('click', 1)\n",
      "('close', 1)\n",
      "('co', 1)\n",
      "('cod', 1)\n",
      "('cold', 1)\n",
      "('colleagues', 1)\n",
      "('collection', 1)\n",
      "('complaints', 1)\n",
      "('concern', 1)\n",
      "('concerned', 1)\n",
      "('concerns', 1)\n",
      "('confirm', 1)\n",
      "('confirmation', 1)\n",
      "('connect', 1)\n",
      "('connecting', 1)\n",
      "('contact', 11)\n",
      "('contacted', 2)\n",
      "('contacting', 1)\n",
      "('could', 1)\n",
      "('couriers', 1)\n",
      "('crashrider', 1)\n",
      "('create', 1)\n",
      "('credit', 1)\n",
      "('cs', 1)\n",
      "('ctrl', 1)\n",
      "('customer', 2)\n",
      "('customers', 1)\n",
      "('customs', 1)\n",
      "('cute', 1)\n",
      "('cutting', 1)\n",
      "('damaged', 1)\n",
      "('danadug', 1)\n",
      "('danjbalkwill', 1)\n",
      "('danny', 1)\n",
      "('darshanhsheth', 3)\n",
      "('date', 5)\n",
      "('day', 4)\n",
      "('days', 1)\n",
      "('delay', 1)\n",
      "('delighted', 1)\n",
      "('deliver', 4)\n",
      "('delivering', 2)\n",
      "('delivery', 6)\n",
      "('department', 2)\n",
      "('desktop', 1)\n",
      "('destination', 1)\n",
      "('details', 6)\n",
      "('device', 1)\n",
      "('did', 1)\n",
      "('didnt', 1)\n",
      "('direct', 1)\n",
      "('directly', 1)\n",
      "('dishanisen', 1)\n",
      "('dmarie99', 1)\n",
      "('do', 4)\n",
      "('doesnt', 5)\n",
      "('dont', 5)\n",
      "('doug', 1)\n",
      "('download', 1)\n",
      "('downloadsr', 1)\n",
      "('dragonflyeye', 2)\n",
      "('drop', 1)\n",
      "('durhambelle', 1)\n",
      "('earlier', 2)\n",
      "('earliest', 1)\n",
      "('edd', 1)\n",
      "('edit', 1)\n",
      "('elaborate', 1)\n",
      "('elidan', 1)\n",
      "('eligible', 1)\n",
      "('else', 1)\n",
      "('email', 5)\n",
      "('emmawrafter', 1)\n",
      "('en', 2)\n",
      "('encourage', 1)\n",
      "('end', 1)\n",
      "('enjoying', 2)\n",
      "('ep', 1)\n",
      "('error', 1)\n",
      "('est', 1)\n",
      "('eumaeusodyssey', 4)\n",
      "('eval', 1)\n",
      "('evening', 1)\n",
      "('exchange', 1)\n",
      "('expected', 1)\n",
      "('experience', 9)\n",
      "('f', 1)\n",
      "('fancy', 1)\n",
      "('features', 1)\n",
      "('feedback', 7)\n",
      "('feel', 4)\n",
      "('filled', 1)\n",
      "('find', 2)\n",
      "('fitbit', 1)\n",
      "('flagging', 1)\n",
      "('following', 2)\n",
      "('for', 50)\n",
      "('form', 1)\n",
      "('forwarded', 1)\n",
      "('found', 1)\n",
      "('free', 2)\n",
      "('friendly', 1)\n",
      "('friendsforever', 1)\n",
      "('friendshipgoals', 1)\n",
      "('from', 2)\n",
      "('frustrating', 1)\n",
      "('fulfilled', 1)\n",
      "('fun', 1)\n",
      "('further', 5)\n",
      "('gerzinal', 1)\n",
      "('get', 3)\n",
      "('getting', 2)\n",
      "('ghostfacezach', 1)\n",
      "('give', 1)\n",
      "('given', 1)\n",
      "('gl', 3)\n",
      "('glad', 3)\n",
      "('goes', 1)\n",
      "('great', 2)\n",
      "('guarantee', 3)\n",
      "('gxb', 1)\n",
      "('had', 1)\n",
      "('halloween', 1)\n",
      "('happen', 1)\n",
      "('happy', 5)\n",
      "('happynewyear', 1)\n",
      "('has', 3)\n",
      "('hasnt', 1)\n",
      "('have', 18)\n",
      "('hb', 4)\n",
      "('hear', 4)\n",
      "('help', 8)\n",
      "('helped', 1)\n",
      "('helpep', 1)\n",
      "('helps', 3)\n",
      "('here', 32)\n",
      "('heres', 1)\n",
      "('hey', 9)\n",
      "('heypardeep', 1)\n",
      "('hg', 2)\n",
      "('hi', 14)\n",
      "('hk', 1)\n",
      "('hope', 3)\n",
      "('how', 3)\n",
      "('hrs', 1)\n",
      "('httpstcoatnhpowqg', 1)\n",
      "('httpstcobxfnsxpf', 1)\n",
      "('httpstcocyqkduakwj', 2)\n",
      "('httpstcodbolxljp', 1)\n",
      "('httpstcodgvsrph', 1)\n",
      "('httpstcoegphbhsxy', 1)\n",
      "('httpstcoevqabgfiz', 1)\n",
      "('httpstcogmrbaot', 1)\n",
      "('httpstcogrr9tfqwc', 1)\n",
      "('httpstcohaplpmejd', 1)\n",
      "('httpstcohaplpmlfhn', 4)\n",
      "('httpstcohaplpmlfhnen', 1)\n",
      "('httpstcohbtdzlmb', 1)\n",
      "('httpstcohrsyfeigu', 1)\n",
      "('httpstcojfhsgq', 1)\n",
      "('httpstcojzphlab', 4)\n",
      "('httpstconuypml', 1)\n",
      "('httpstconxgaalzhis', 1)\n",
      "('httpstcoqypasjve', 1)\n",
      "('httpstcoskgzkjcdng', 1)\n",
      "('httpstcosmli9yxdaw', 1)\n",
      "('httpstcoturyufp', 1)\n",
      "('httpstcotyqqajrzk', 1)\n",
      "('httpstcouwnabciif', 1)\n",
      "('httpstcovihgdspeur', 1)\n",
      "('httpstcovlvfjrnn9', 2)\n",
      "('httpstcowlfycbapb', 1)\n",
      "('httpstcoyhhwiftlm', 1)\n",
      "('httpstcoyjpi9grhe', 5)\n",
      "('httpstcoywrqdfkba', 1)\n",
      "('httpstcoz9jaqgy', 1)\n",
      "('httpstcozwrezyrzu', 1)\n",
      "('i', 9)\n",
      "('identify', 1)\n",
      "('if', 22)\n",
      "('im', 13)\n",
      "('improve', 1)\n",
      "('in', 12)\n",
      "('inconvenience', 2)\n",
      "('incorrect', 1)\n",
      "('indicate', 1)\n",
      "('indicates', 1)\n",
      "('info', 4)\n",
      "('information', 1)\n",
      "('instances', 1)\n",
      "('interest', 2)\n",
      "('internally', 1)\n",
      "('into', 6)\n",
      "('investigate', 1)\n",
      "('is', 13)\n",
      "('isnt', 2)\n",
      "('issue', 2)\n",
      "('issues', 1)\n",
      "('it', 17)\n",
      "('item', 5)\n",
      "('items', 1)\n",
      "('its', 3)\n",
      "('itsjossha', 2)\n",
      "('ive', 1)\n",
      "('izzyscott', 1)\n",
      "('ja', 3)\n",
      "('jaemulaa', 1)\n",
      "('jeedas', 1)\n",
      "('jj', 1)\n",
      "('jo', 6)\n",
      "('john', 1)\n",
      "('joke', 1)\n",
      "('joyfulneesh', 1)\n",
      "('jrc9', 1)\n",
      "('jtreadway', 1)\n",
      "('katmcor', 1)\n",
      "('kd', 1)\n",
      "('keep', 7)\n",
      "('keeps', 1)\n",
      "('kindakuls', 1)\n",
      "('kindle', 3)\n",
      "('kindly', 1)\n",
      "('knooow', 1)\n",
      "('know', 13)\n",
      "('knowing', 1)\n",
      "('kstefl', 1)\n",
      "('late', 2)\n",
      "('leave', 3)\n",
      "('let', 7)\n",
      "('letting', 2)\n",
      "('lg', 1)\n",
      "('li', 1)\n",
      "('like', 7)\n",
      "('lil', 1)\n",
      "('link', 6)\n",
      "('lisadeee', 1)\n",
      "('list', 1)\n",
      "('lizzieejones', 1)\n",
      "('location', 1)\n",
      "('longer', 1)\n",
      "('look', 7)\n",
      "('looked', 1)\n",
      "('looking', 2)\n",
      "('love', 1)\n",
      "('magsophazjon', 2)\n",
      "('mailstosandeep', 1)\n",
      "('make', 2)\n",
      "('manage', 2)\n",
      "('mark', 1)\n",
      "('matt', 1)\n",
      "('mattlinsley', 1)\n",
      "('may', 2)\n",
      "('mcp', 1)\n",
      "('me', 3)\n",
      "('media', 1)\n",
      "('medicine', 1)\n",
      "('membership', 1)\n",
      "('menu', 1)\n",
      "('method', 1)\n",
      "('missed', 1)\n",
      "('mm', 1)\n",
      "('mobile', 1)\n",
      "('modify', 1)\n",
      "('moment', 1)\n",
      "('more', 3)\n",
      "('most', 3)\n",
      "('mpos', 1)\n",
      "('mrpandit', 1)\n",
      "('much', 2)\n",
      "('naijadrew', 1)\n",
      "('need', 4)\n",
      "('never', 1)\n",
      "('new', 3)\n",
      "('newest', 1)\n",
      "('next', 1)\n",
      "('nf', 1)\n",
      "('night', 1)\n",
      "('no', 5)\n",
      "('not', 4)\n",
      "('now', 3)\n",
      "('number', 1)\n",
      "('of', 3)\n",
      "('off', 1)\n",
      "('oh', 1)\n",
      "('on', 14)\n",
      "('online', 1)\n",
      "('only', 1)\n",
      "('open', 1)\n",
      "('options', 3)\n",
      "('or', 4)\n",
      "('order', 10)\n",
      "('orders', 1)\n",
      "('other', 1)\n",
      "('our', 10)\n",
      "('out', 6)\n",
      "('over', 1)\n",
      "('packages', 1)\n",
      "('packaging', 1)\n",
      "('page', 1)\n",
      "('pass', 2)\n",
      "('patience', 1)\n",
      "('pawansbaish', 2)\n",
      "('pawsome', 1)\n",
      "('payment', 2)\n",
      "('phone', 2)\n",
      "('phonechat', 1)\n",
      "('picture', 1)\n",
      "('pk', 1)\n",
      "('place', 1)\n",
      "('plainbananas', 1)\n",
      "('playlist', 1)\n",
      "('please', 20)\n",
      "('pls', 3)\n",
      "('pm', 1)\n",
      "('post', 1)\n",
      "('posted', 6)\n",
      "('ppramod9', 1)\n",
      "('pretty', 1)\n",
      "('prime', 1)\n",
      "('process', 1)\n",
      "('product', 1)\n",
      "('profgambs', 1)\n",
      "('promised', 1)\n",
      "('provided', 3)\n",
      "('puppy', 1)\n",
      "('purchased', 1)\n",
      "('put', 1)\n",
      "('qualify', 1)\n",
      "('quality', 1)\n",
      "('queenattallah', 1)\n",
      "('questions', 2)\n",
      "('quickly', 1)\n",
      "('ra', 1)\n",
      "('ratbones', 1)\n",
      "('rather', 2)\n",
      "('reach', 3)\n",
      "('reading', 1)\n",
      "('real', 1)\n",
      "('receive', 1)\n",
      "('received', 1)\n",
      "('receiver', 1)\n",
      "('recent', 1)\n",
      "('recommend', 1)\n",
      "('redeeming', 1)\n",
      "('refund', 2)\n",
      "('refunds', 1)\n",
      "('regarding', 1)\n",
      "('regret', 1)\n",
      "('relevant', 1)\n",
      "('repeated', 1)\n",
      "('replacement', 1)\n",
      "('replacements', 1)\n",
      "('reply', 2)\n",
      "('report', 2)\n",
      "('reported', 1)\n",
      "('request', 4)\n",
      "('requested', 2)\n",
      "('resolved', 1)\n",
      "('return', 3)\n",
      "('returnexchange', 1)\n",
      "('returnreplacement', 1)\n",
      "('returns', 1)\n",
      "('review', 4)\n",
      "('reviewed', 1)\n",
      "('reviews', 1)\n",
      "('right', 1)\n",
      "('rm', 1)\n",
      "('rockerdharm', 1)\n",
      "('ronaldorlemes', 1)\n",
      "('roxsi9', 1)\n",
      "('rs', 2)\n",
      "('rw', 1)\n",
      "('rwwishart', 1)\n",
      "('saififiroz', 2)\n",
      "('same', 1)\n",
      "('sb', 1)\n",
      "('scan', 3)\n",
      "('schoey99', 1)\n",
      "('see', 3)\n",
      "('seeing', 1)\n",
      "('seentitties', 1)\n",
      "('select', 1)\n",
      "('seller', 5)\n",
      "('send', 1)\n",
      "('sent', 1)\n",
      "('separate', 1)\n",
      "('service', 1)\n",
      "('settings', 1)\n",
      "('sgtwinters', 1)\n",
      "('sh', 6)\n",
      "('shall', 1)\n",
      "('share', 1)\n",
      "('shared', 1)\n",
      "('sharing', 1)\n",
      "('sharrypigtails', 1)\n",
      "('ship', 1)\n",
      "('shipment', 1)\n",
      "('shirt', 1)\n",
      "('shopping', 3)\n",
      "('shoppingsr', 1)\n",
      "('should', 2)\n",
      "('shout', 1)\n",
      "('shoutout', 1)\n",
      "('showing', 1)\n",
      "('site', 3)\n",
      "('sj', 6)\n",
      "('sjbooktweeter', 2)\n",
      "('so', 18)\n",
      "('social', 1)\n",
      "('some', 2)\n",
      "('soon', 2)\n",
      "('sorry', 21)\n",
      "('sorted', 2)\n",
      "('sound', 1)\n",
      "('sounds', 1)\n",
      "('speak', 1)\n",
      "('specific', 1)\n",
      "('spotify', 1)\n",
      "('sr', 3)\n",
      "('stadesse', 1)\n",
      "('start', 1)\n",
      "('status', 2)\n",
      "('stay', 1)\n",
      "('stayhealthy', 1)\n",
      "('steps', 4)\n",
      "('still', 1)\n",
      "('stock', 2)\n",
      "('stopped', 1)\n",
      "('submit', 1)\n",
      "('substantial', 1)\n",
      "('supervisor', 1)\n",
      "('support', 3)\n",
      "('sure', 4)\n",
      "('surprise', 1)\n",
      "('sydneycohenour', 1)\n",
      "('tamarastampone', 1)\n",
      "('td', 1)\n",
      "('team', 2)\n",
      "('teams', 2)\n",
      "('text', 1)\n",
      "('than', 1)\n",
      "('thank', 1)\n",
      "('thanks', 11)\n",
      "('that', 18)\n",
      "('thats', 2)\n",
      "('thblomme', 1)\n",
      "('the', 65)\n",
      "('thedexterouz', 1)\n",
      "('them', 1)\n",
      "('then', 3)\n",
      "('there', 2)\n",
      "('these', 4)\n",
      "('they', 1)\n",
      "('things', 1)\n",
      "('thirdparty', 2)\n",
      "('this', 27)\n",
      "('thorpperrow', 1)\n",
      "('through', 3)\n",
      "('time', 3)\n",
      "('tm', 2)\n",
      "('to', 64)\n",
      "('tomorrow', 2)\n",
      "('tomroe9', 1)\n",
      "('tracking', 5)\n",
      "('transit', 1)\n",
      "('tried', 1)\n",
      "('trouble', 3)\n",
      "('truly', 2)\n",
      "('try', 3)\n",
      "('trying', 1)\n",
      "('tuned', 1)\n",
      "('twitter', 2)\n",
      "('typically', 2)\n",
      "('unable', 2)\n",
      "('understand', 1)\n",
      "('unlinkinglinking', 1)\n",
      "('until', 2)\n",
      "('uoduckscotty', 1)\n",
      "('up', 2)\n",
      "('update', 2)\n",
      "('updated', 1)\n",
      "('updates', 3)\n",
      "('upride', 1)\n",
      "('us', 28)\n",
      "('use', 1)\n",
      "('using', 2)\n",
      "('very', 1)\n",
      "('via', 4)\n",
      "('vickyfilmydev', 1)\n",
      "('video', 2)\n",
      "('view', 1)\n",
      "('visit', 2)\n",
      "('vlslt', 1)\n",
      "('vs', 1)\n",
      "('waiting', 1)\n",
      "('wan', 1)\n",
      "('want', 2)\n",
      "('was', 5)\n",
      "('way', 2)\n",
      "('we', 23)\n",
      "('website', 1)\n",
      "('wed', 5)\n",
      "('week', 1)\n",
      "('well', 9)\n",
      "('went', 1)\n",
      "('were', 9)\n",
      "('weve', 1)\n",
      "('what', 5)\n",
      "('whats', 1)\n",
      "('when', 5)\n",
      "('where', 2)\n",
      "('which', 1)\n",
      "('while', 2)\n",
      "('will', 6)\n",
      "('windows', 1)\n",
      "('with', 6)\n",
      "('within', 1)\n",
      "('wj', 4)\n",
      "('work', 1)\n",
      "('working', 1)\n",
      "('worst', 1)\n",
      "('written', 1)\n",
      "('wrong', 2)\n",
      "('wyour', 1)\n",
      "('year', 2)\n",
      "('you', 60)\n",
      "('youd', 2)\n",
      "('your', 33)\n",
      "('youre', 2)\n",
      "('yourself', 1)\n",
      "('yp', 2)\n",
      "('zesaiyan', 1)\n",
      "('\\u200bhey', 1)\n",
      "('😊', 1)\n",
      "('😌', 1)\n",
      "('😷😷', 1)\n",
      "('🙋', 1)\n"
     ]
    }
   ],
   "source": [
    "data_MapReduce = cleandata.map(lambda word: (word, 1)).reduceByKey(lambda v1, v2: v1+v2).sortByKey()          \n",
    "\n",
    "for i in data_MapReduce.collect(): \n",
    "  print (i)\n",
    "\n",
    "data_MapReduce1 = data_MapReduce.toDF().withColumnRenamed(\"_1\",\"Word\").withColumnRenamed(\"_2\",\"Frequency\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "55544f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting to csv file \n",
    "\n",
    "data_MapReduce1.toPandas().to_csv('/Users/hoangnha218/Desktop/IDS561_HW2/Task1.csv',mode = 'w', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d6377f",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c1a9e668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load find_text data file \n",
    "text = spark.read.csv(\"find_text.csv\", header = \"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7736639a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Merging Amazon data and text data on \"id_str\" to fill in the \"text\" column\n",
    "\n",
    "amazon3 = amazon1.select('id_str', 'text_')\n",
    "\n",
    "Amazon_Responded_Oct05 = amazon3.rdd\n",
    "\n",
    "find_text = text.rdd\n",
    "\n",
    "mergedRdd = find_text.join(Amazon_Responded_Oct05)\n",
    "\n",
    "mergedRdd.collect()\n",
    "\n",
    "\n",
    "finalRdd = mergedRdd.flatMap(lambda x: [(x[0], v) for v in x[1]])\n",
    "\n",
    "df= finalRdd.toDF().withColumnRenamed(\"_1\",\"id_str\").withColumnRenamed(\"_2\",\"text\")\n",
    "\n",
    "df1 = df.filter(df.text. isNotNull())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fece54dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Exporting to csv file\n",
    "\n",
    "df1.toPandas().to_csv('/Users/hoangnha218/Desktop/IDS561_HW2/Task2.csv',mode = 'w', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a18131",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

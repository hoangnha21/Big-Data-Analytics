{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPTThmWd+fh0NHyagTAEnXV"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"_Bjjdi0uH43F"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","%cd /content/drive/My Drive/IDS561_final_project/yelp_dataset\n","!ls\n","!pwd"]},{"cell_type":"markdown","source":["# Install Spark and Load Dataframe"],"metadata":{"id":"C4aoOO3lIT0u"}},{"cell_type":"code","source":["# Download and set up Java\n","!apt-get install openjdk-8-jdk-headless -qq > /dev/null"],"metadata":{"id":"cXPyuaPGH-wk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Get Spark installer (check the path on spark.apache.org)\n","!wget -v https://dlcdn.apache.org/spark/spark-3.3.2/spark-3.3.2-bin-hadoop3.tgz"],"metadata":{"id":"Qx8ErhvWIAtB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Untar the Spark installer\n","!tar -xvf spark-3.3.2-bin-hadoop3.tgz\n","\n","# Install findspark - python library to find Spark\n","!pip install -q findspark\n","\n","# Set environment variables\n","# Set Java and Spark home based on the location where they are stored\n","import os\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n","os.environ[\"SPARK_HOME\"] = \"/content/drive/My Drive/IDS561_final_project/yelp_dataset/spark-3.3.2-bin-hadoop3\"\n","\n","# Create local Spark session\n","import findspark\n","findspark.init()\n","from pyspark.sql import SparkSession\n","spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"],"metadata":{"id":"CBZ9VixWITL5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Import Libraries"],"metadata":{"id":"V3rwZHMLIe54"}},{"cell_type":"code","source":["import re\n","import sys\n","import string\n","import pandas as pd\n","from pyspark import SparkConf, SparkContext, HiveContext\n","from pyspark.mllib.recommendation import ALS, MatrixFactorizationModel, Rating\n","from heapq import nlargest\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# Import libraries for spark\n","from pyspark import *\n","from pyspark.python.pyspark.shell import spark\n","from pyspark.sql.functions import *\n","from datetime import datetime\n","from pyspark.sql.functions import udf, to_date, to_utc_timestamp, lit, col\n","from pyspark.sql.types import StringType, DateType\n","from pyspark import SparkContext\n","from pyspark.sql import SQLContext\n","from pyspark.sql.functions import split,explode\n","from pyspark.sql.functions import *\n","from pyspark.sql.functions import udf\n","from pyspark.sql.types import IntegerType\n","\n","# imort libraries for pyspark.ml features and clustering\n","from pyspark.mllib.classification import SVMModel, SVMWithSGD\n","from pyspark.mllib.regression import LabeledPoint\n","from pyspark.mllib.linalg import Vectors as MLLibVectors\n","from pyspark.ml import Pipeline\n","from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n","from pyspark.ml.feature import *\n","from pyspark.ml.feature import IDF\n","from pyspark.ml.tuning import CrossValidator\n","from pyspark.ml.tuning import ParamGridBuilder\n","from pyspark.ml.feature import StandardScaler\n","from pyspark.ml.clustering import KMeans\n","from pyspark.ml.evaluation import ClusteringEvaluator\n","\n","\n","# import nltk library for natural language processing\n","from nltk.stem.porter import *\n","from nltk.tokenize import word_tokenize, sent_tokenize\n","from nltk.corpus import stopwords\n","\n","# import wordcloud library for visualizing displays of text data\n","from wordcloud import WordCloud, STOPWORDS"],"metadata":{"id":"92KZrWdxIXmp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Open local Spark session\n","import findspark\n","findspark.init()\n","from pyspark.sql import SparkSession\n","sprk = SparkSession.builder.master(\"local[*]\").getOrCreate()\n","#import data into dataframe\n","df_review = spark.read.json('.../yelp_dataset/review.json')\n","df_business = spark.read.json('.../business.json')\n","df_user = spark.read.json('/content/drive/My Drive/IDS561_final_project/yelp_dataset/user.json')"],"metadata":{"id":"BhV5ymIqIlWU"},"execution_count":null,"outputs":[]}]}
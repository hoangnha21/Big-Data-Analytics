{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNphBG+5SbyzQZqi7jXuByN"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"Lf3Az4CzpLYs"},"source":["# **II.Text Pre-processing**\n","\n","For sentiment analysis, we first need to pre-process our comments"]},{"cell_type":"markdown","metadata":{"id":"4hmU6CAIHOGE"},"source":["**STEP 1. Remove punctuations**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sWBoryfHq-ry"},"outputs":[],"source":["def remove_punct(text):\n","    regex = re.compile('[' + re.escape(string.punctuation) + '0-9\\\\r\\\\t\\\\n]')\n","    no_pun = regex.sub(\" \", text)\n","    return no_pun"]},{"cell_type":"markdown","metadata":{"id":"3TlLVB2oHlcl"},"source":["**STEP 2. Classify reviews as positive or negative sentiment, where star greater than 3 is labeled as 1.** **bold text**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B0oQFvOpHe5R"},"outputs":[],"source":["def convert_rating(rating):\n","    star_ratings = int(rating)\n","    if rating >=3: return 1\n","    else: return 0\n","\n","# functions to remove punctuation and convert star ratings\n","pun_remove = udf(lambda x: remove_punct(x))\n","convert = udf(lambda x: convert_rating(x))\n","\n","# apply above functions to our datasets\n","processed_review = df_review.select('review_id', pun_remove('text'), convert('stars'))\n","\n","processed_review = processed_review.withColumnRenamed('<lambda>(text)', 'text')\\\n","                     .withColumn('label', processed_review[\"<lambda>(stars)\"].cast(IntegerType()))\\\n","                     .drop('<lambda>(stars)')\\\n","                     .limit(1000000)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":283477,"status":"ok","timestamp":1693510112422,"user":{"displayName":"Nhã Nguyễn Hoàng","userId":"16908522501194289483"},"user_tz":300},"id":"zf9cZ5sgJUIp","outputId":"7b1cbab2-f27e-4987-deaa-7d31c3be586b"},"outputs":[{"output_type":"stream","name":"stdout","text":["+--------------------+--------------------+-----+\n","|           review_id|                text|label|\n","+--------------------+--------------------+-----+\n","|KU_O5udG6zpxOg-Vc...|If you decide to ...|    1|\n","|BiTunyQ73aT9WBnpR...|I ve taken a lot ...|    1|\n","|saUsX_uimxRlCVr67...|Family diner  Had...|    1|\n","|AqPFMleE6RsU23_au...|Wow   Yummy  diff...|    1|\n","|Sx8TMOWLNuJBWer-0...|Cute interior and...|    1|\n","+--------------------+--------------------+-----+\n","only showing top 5 rows\n","\n"]}],"source":["#Display reviews after processing\n","processed_review.show(5)"]},{"cell_type":"markdown","metadata":{"id":"RfYlXbBWJmVc"},"source":["**STEP 3. Tokenize comments and remove stop words**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ak2KU7zMJs_N"},"outputs":[],"source":["# tokenize reviews\n","tokenize = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n","tokenized_review = tokenize.transform(processed_review)\n","\n","# remove stop words\n","remove_stopword = StopWordsRemover(inputCol='words', outputCol='words_new')\n","tokenized_review = remove_stopword.transform(tokenized_review)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q3r4-MdiKe1Y","outputId":"216c4db7-ced4-4f7f-cbee-253b82985514","executionInfo":{"status":"ok","timestamp":1693510394526,"user_tz":300,"elapsed":281906,"user":{"displayName":"Nhã Nguyễn Hoàng","userId":"16908522501194289483"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["+--------------------+--------------------+-----+--------------------+--------------------+\n","|           review_id|                text|label|               words|           words_new|\n","+--------------------+--------------------+-----+--------------------+--------------------+\n","|KU_O5udG6zpxOg-Vc...|If you decide to ...|    1|[if, you, decide,...|[decide, eat, , a...|\n","|BiTunyQ73aT9WBnpR...|I ve taken a lot ...|    1|[i, ve, taken, a,...|[ve, taken, lot, ...|\n","|saUsX_uimxRlCVr67...|Family diner  Had...|    1|[family, diner, ,...|[family, diner, ,...|\n","|AqPFMleE6RsU23_au...|Wow   Yummy  diff...|    1|[wow, , , yummy, ...|[wow, , , yummy, ...|\n","|Sx8TMOWLNuJBWer-0...|Cute interior and...|    1|[cute, interior, ...|[cute, interior, ...|\n","+--------------------+--------------------+-----+--------------------+--------------------+\n","only showing top 5 rows\n","\n"]}],"source":["#Display reviews after tokenization and removal of stop words\n","tokenized_review.show(5)"]},{"cell_type":"markdown","metadata":{"id":"7K9bellOKvtC"},"source":["**STEP 4: CountVectorisation and tf-Idf (term frequency and inverse document frequency)**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Hm4kYMP-Kue2"},"outputs":[],"source":["# CountVectorization\n","CountVec = CountVectorizer(inputCol='words_new', outputCol='tf')\n","CountVec_model = CountVec.fit(tokenized_review)\n","count_vectorized_reviews = CountVec_model.transform(tokenized_review)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"59vbRo4-Lcvm"},"outputs":[],"source":["# tf-idf\n","tf_idf = IDF().setInputCol('tf').setOutputCol('tf_idf')\n","tf_idf_model = tf_idf.fit(count_vectorized_reviews)\n","tf_idf_review = tf_idf_model.transform(count_vectorized_reviews)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"9RidemseL3ZF"},"outputs":[],"source":["#Display reviews after countvectorization and tfidf\n","tf_idf_review.show(5)"]}]}
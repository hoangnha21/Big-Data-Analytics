{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oa_gp7864VSq"
      },
      "source": [
        "# **TEXT ANALYSIS: SENTIMENTAL ANALYSIS PRE PROCESSING**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "am947nyE4wnR"
      },
      "source": [
        "**For sentimental analysis, we first need to pre process our comments**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYxkFNF_48Ml"
      },
      "source": [
        "**STEP 1. Remove punctuations**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "teoCVsn64rHd"
      },
      "outputs": [],
      "source": [
        "def remove_punct(text):\n",
        "    regex = re.compile('[' + re.escape(string.punctuation) + '0-9\\\\r\\\\t\\\\n]')\n",
        "    nopunct = regex.sub(\" \", text)\n",
        "    return nopunct"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tl0N_amS5KYW"
      },
      "source": [
        "**STEP 2. Split the ratings at threshold =3 to classify them as positive or negative sentiment**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "AS25C9Ji5H4S"
      },
      "outputs": [],
      "source": [
        "def convert_rating(rating):\n",
        "    rating = int(rating)\n",
        "    if rating >=3: return 1\n",
        "    else: return 0\n",
        "\n",
        "# Generating user-defined functions to remove punctuation and convert rating\n",
        "punct_remover = udf(lambda x: remove_punct(x))\n",
        "rating_convert = udf(lambda x: convert_rating(x))\n",
        "\n",
        "# apply to review raw data\n",
        "review_df = yelp_review.select('review_id', punct_remover('text'), rating_convert('stars'))\n",
        "\n",
        "review_df = review_df.withColumnRenamed('<lambda>(text)', 'text')\\\n",
        "                     .withColumn('label', review_df[\"<lambda>(stars)\"].cast(IntegerType()))\\\n",
        "                     .drop('<lambda>(stars)')\\\n",
        "                     .limit(1000000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1IeAYbf-d0MX",
        "outputId": "80c5b59f-e286-45c2-c85b-c06b5cd22b22"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------+--------------------+-----+\n",
            "|           review_id|                text|label|\n",
            "+--------------------+--------------------+-----+\n",
            "|KU_O5udG6zpxOg-Vc...|If you decide to ...|    1|\n",
            "|BiTunyQ73aT9WBnpR...|I ve taken a lot ...|    1|\n",
            "|saUsX_uimxRlCVr67...|Family diner  Had...|    1|\n",
            "|AqPFMleE6RsU23_au...|Wow   Yummy  diff...|    1|\n",
            "|Sx8TMOWLNuJBWer-0...|Cute interior and...|    1|\n",
            "+--------------------+--------------------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "review_df.show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__HZ4i3A90Xf"
      },
      "source": [
        "**STEP 3. Tokenizing the comments and removing stop words**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "wQ58GOd690Dl"
      },
      "outputs": [],
      "source": [
        "# tokenize\n",
        "tok = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
        "review_tokenized = tok.transform(review_df)\n",
        "\n",
        "# remove stop words\n",
        "stopword_rm = StopWordsRemover(inputCol='words', outputCol='words_new')\n",
        "review_tokenized = stopword_rm.transform(review_tokenized)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GyEJkqAc-aMg",
        "outputId": "59ecd92c-ba28-41ab-ca13-b5be38ed19b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------+--------------------+-----+--------------------+--------------------+\n",
            "|           review_id|                text|label|               words|           words_new|\n",
            "+--------------------+--------------------+-----+--------------------+--------------------+\n",
            "|KU_O5udG6zpxOg-Vc...|If you decide to ...|    1|[if, you, decide,...|[decide, eat, , a...|\n",
            "|BiTunyQ73aT9WBnpR...|I ve taken a lot ...|    1|[i, ve, taken, a,...|[ve, taken, lot, ...|\n",
            "|saUsX_uimxRlCVr67...|Family diner  Had...|    1|[family, diner, ,...|[family, diner, ,...|\n",
            "|AqPFMleE6RsU23_au...|Wow   Yummy  diff...|    1|[wow, , , yummy, ...|[wow, , , yummy, ...|\n",
            "|Sx8TMOWLNuJBWer-0...|Cute interior and...|    1|[cute, interior, ...|[cute, interior, ...|\n",
            "+--------------------+--------------------+-----+--------------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "review_tokenized.show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbwbTPrU9IG8"
      },
      "source": [
        "**FEATURE EXTRACTION**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MwGx2MJc9LJ8"
      },
      "source": [
        "For feature selection, we have used CountVectorisation and tf-Idf (term frequency and inverse document frequency)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ing2tQGw9i_L"
      },
      "source": [
        "**STEP 4: Count vectorisation** helps to extract features by converting text into vectors based on the count of its appearance.\n",
        "It is useful for multiple documents to provide a matrix."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "OygKj0Tj9ZI2"
      },
      "outputs": [],
      "source": [
        "# count vectorizer\n",
        "cv = CountVectorizer(inputCol='words_new', outputCol='tf')\n",
        "cvModel = cv.fit(review_tokenized)\n",
        "count_vectorized = cvModel.transform(review_tokenized)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zh1jljAi-bsB",
        "outputId": "b54836a3-7024-46dd-bd71-d2c3fe29c2d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------+--------------------+-----+--------------------+--------------------+--------------------+\n",
            "|           review_id|                text|label|               words|           words_new|                  tf|\n",
            "+--------------------+--------------------+-----+--------------------+--------------------+--------------------+\n",
            "|KU_O5udG6zpxOg-Vc...|If you decide to ...|    1|[if, you, decide,...|[decide, eat, , a...|(202063,[0,1,2,6,...|\n",
            "|BiTunyQ73aT9WBnpR...|I ve taken a lot ...|    1|[i, ve, taken, a,...|[ve, taken, lot, ...|(202063,[0,7,14,1...|\n",
            "|saUsX_uimxRlCVr67...|Family diner  Had...|    1|[family, diner, ,...|[family, diner, ,...|(202063,[0,2,3,13...|\n",
            "|AqPFMleE6RsU23_au...|Wow   Yummy  diff...|    1|[wow, , , yummy, ...|[wow, , , yummy, ...|(202063,[0,11,28,...|\n",
            "|Sx8TMOWLNuJBWer-0...|Cute interior and...|    1|[cute, interior, ...|[cute, interior, ...|(202063,[0,2,4,6,...|\n",
            "+--------------------+--------------------+-----+--------------------+--------------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "count_vectorized.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "9WBHfcF7-a2k"
      },
      "outputs": [],
      "source": [
        "# tf-idf\n",
        "idf = IDF().setInputCol('tf').setOutputCol('tfidf')\n",
        "tfidfModel = idf.fit(count_vectorized)\n",
        "tfidf_df = tfidfModel.transform(count_vectorized)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8m84qnmd4S0w",
        "outputId": "5a208ea8-f872-48ea-cfb8-a2b1fefd54a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------+--------------------+-----+--------------------+--------------------+--------------------+--------------------+\n",
            "|           review_id|                text|label|               words|           words_new|                  tf|               tfidf|\n",
            "+--------------------+--------------------+-----+--------------------+--------------------+--------------------+--------------------+\n",
            "|KU_O5udG6zpxOg-Vc...|If you decide to ...|    1|[if, you, decide,...|[decide, eat, , a...|(202063,[0,1,2,6,...|(202063,[0,1,2,6,...|\n",
            "|BiTunyQ73aT9WBnpR...|I ve taken a lot ...|    1|[i, ve, taken, a,...|[ve, taken, lot, ...|(202063,[0,7,14,1...|(202063,[0,7,14,1...|\n",
            "|saUsX_uimxRlCVr67...|Family diner  Had...|    1|[family, diner, ,...|[family, diner, ,...|(202063,[0,2,3,13...|(202063,[0,2,3,13...|\n",
            "|AqPFMleE6RsU23_au...|Wow   Yummy  diff...|    1|[wow, , , yummy, ...|[wow, , , yummy, ...|(202063,[0,11,28,...|(202063,[0,11,28,...|\n",
            "|Sx8TMOWLNuJBWer-0...|Cute interior and...|    1|[cute, interior, ...|[cute, interior, ...|(202063,[0,2,4,6,...|(202063,[0,2,4,6,...|\n",
            "+--------------------+--------------------+-----+--------------------+--------------------+--------------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "tfidf_df.show(5)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "nXXAQwylEqeT",
        "qLUs7M34E1Ve",
        "oa_gp7864VSq",
        "D-BnLiDC159i",
        "51TG0eE8BUc-",
        "wQ9rBFf0rMMe",
        "lPBW6b0WuXS7",
        "MoMtkiNtrW9f"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "VNIplsYe1HeN",
   "metadata": {
    "id": "VNIplsYe1HeN"
   },
   "outputs": [],
   "source": [
    "#importing the libraries\n",
    "import math\n",
    "import string\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "OhXJZSTo1PKo",
   "metadata": {
    "id": "OhXJZSTo1PKo"
   },
   "outputs": [],
   "source": [
    "#Reading Text File \n",
    "with open('temperatures.txt') as f: \n",
    "    lines = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "feB1Ij0X1bwz",
   "metadata": {
    "id": "feB1Ij0X1bwz"
   },
   "outputs": [],
   "source": [
    "#Data Cleaning Function\n",
    "def Clean(list):\n",
    "\n",
    "    date1 = []\n",
    "    temp1 = []\n",
    "    date2 = []\n",
    "    temp2 = []\n",
    "    #print(list[0])\n",
    "\n",
    "    for item in list:\n",
    "        date1.append(int(item[0][1:7]))   #Index of the Year Element\n",
    "        temp1.append(int(item[1][:-2]))   #Index of the Temperature\n",
    "        date2.append(int(item[2][1:7]))   #Index of the Year Element\n",
    "        temp2.append(int(item[3][:-1]))   #Index of the Temperature\n",
    "        #print(lt2[0])\n",
    "\n",
    "    final_date=date1+date2                #Merging the Year variables\n",
    "    final_temp=temp1+temp2                #Merging the Temperature variables\n",
    "    date = pd.DataFrame(final_date)\n",
    "    date.columns = [\"Year\"]\n",
    "    date['Temp'] = final_temp\n",
    "    date[\"Year\"] = date[\"Year\"]//100      #Returns the year value\n",
    "\n",
    "    return(date)                          #Returns the final dataset of 2000 rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "mY5798Gq1gMN",
   "metadata": {
    "id": "mY5798Gq1gMN"
   },
   "outputs": [],
   "source": [
    "#Function to Split the data into two sets\n",
    "def DataSplit(date):\n",
    "    part1 = date.iloc[0:1000,:]       #Dataset of first 1000 rows\n",
    "    part2 = date.iloc[1000:,:]        #Dataset of remaining 1000 rows\n",
    "    return(part1, part2)              #Returning split datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "GOsaCz4U1j1z",
   "metadata": {
    "id": "GOsaCz4U1j1z"
   },
   "outputs": [],
   "source": [
    "#Function for Mapper\n",
    "def mapper(part):\n",
    "    map_file = {}\n",
    "\n",
    "    for i in part[\"Year\"].tolist():\n",
    "        map_file[i] = part[part[\"Year\"]==i][\"Temp\"].tolist()             #Mappng the year\n",
    "    return(map_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "X3ffmQXH1qJs",
   "metadata": {
    "id": "X3ffmQXH1qJs"
   },
   "outputs": [],
   "source": [
    "#Function for sorting with ascending order\n",
    "def sorting(dict):\n",
    "    dict_final = sorted(dict)\n",
    "    return(dict_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "wAeAOHLx1tAg",
   "metadata": {
    "id": "wAeAOHLx1tAg"
   },
   "outputs": [],
   "source": [
    "#Function for the partitioning the data\n",
    "def partition(dict_final):\n",
    "    dict1 = []\n",
    "    dict2 = []\n",
    "    for i in range(11):\n",
    "        if(dict_final[i][0]<=2015):           #Partition based on year <= 2015\n",
    "            dict1.append(dict_final[i])\n",
    "        else:                                 #Partition based on year after 2015\n",
    "            dict2.append(dict_final[i])\n",
    "    return(dict1,dict2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "jfUF7pGr1vof",
   "metadata": {
    "id": "jfUF7pGr1vof"
   },
   "outputs": [],
   "source": [
    "#Function for reducer 1\n",
    "def reducer1(dict1):\n",
    "\n",
    "    max_dict1 = []\n",
    "    for i in range(6):\n",
    "        max_dict1.append((dict1[i][0],max(dict1[i][1])))\n",
    "\n",
    "    return(max_dict1)\n",
    "\n",
    "\n",
    "#Function for Reducer 2\n",
    "def reducer2(dict2):\n",
    "\n",
    "    max_dict2 = []\n",
    "    for i in range(5):\n",
    "        max_dict2.append((dict2[i][0],max(dict2[i][1])))\n",
    "\n",
    "    return(max_dict2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "TOX_DSfd13Cs",
   "metadata": {
    "id": "TOX_DSfd13Cs"
   },
   "outputs": [],
   "source": [
    "#Function for combining the results\n",
    "def combine(max_dict1,max_dict2):\n",
    "\n",
    "    list_final = max_dict1 + max_dict2\n",
    "    final_df = pd.DataFrame(list_final, columns = (\"Year\", \"Max Temperature\"))\n",
    "\n",
    "    return(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0adbc7a7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "0adbc7a7",
    "outputId": "4ee5ed0e-7bfb-4c75-c18a-2cf6dfcdcfac"
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (3864946269.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/var/folders/y3/zg8_bjc127s_qr_j864sbblr0000gn/T/ipykernel_66659/3864946269.py\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    lines = f.readlines()\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "#Main Function\n",
    "def main():\n",
    "\n",
    "    with open('temperatures.txt') as f: \n",
    "    lines = f.readlines()\n",
    "\n",
    "    date = Clean(list)        # Calling the Clean function\n",
    "    #print(date)\n",
    "\n",
    "    part1, part2 = DataSplit(date)    #Calling the DataSplit Function\n",
    "    #print(part1)\n",
    "    #print(part2)\n",
    "\n",
    "    map_file1 = mapper(part1)         #Calling the mapper function\n",
    "    map_file2 = mapper(part2)         #Calling the mapper function\n",
    "    #print(out1)\n",
    "    #print(out2)\n",
    "\n",
    "    dict_merge = {**map_file1,**map_file2}      #merging the two dictionaries\n",
    "    dict = dict_merge.items()                   #Calling the merge function\n",
    "    #print(len(dict))\n",
    "    dict_final = sorting(dict)                  #Calling the sorting function\n",
    "\n",
    "    #print(final_dict)\n",
    "    dict1, dict2 = partition(dict_final)        #Calling the partition function\n",
    "    #print(dict1)\n",
    "    #print(dict2)\n",
    "\n",
    "    max_dict1 = reducer1(dict1)                 #Calling the reducer1 function\n",
    "    max_dict2 = reducer2(dict2)                 #Calling the reducer2 function\n",
    "    #print(max_dict1)\n",
    "    #print(max_dict2)\n",
    "\n",
    "    final_df = combine(max_dict1,max_dict2)     #Calling the combine function\n",
    "    print(final_df)\n",
    "    final_df.to_csv('output.csv', index = False)     #Creating the .csv file\n",
    "    files.download('output.csv')\n",
    "\n",
    "#Calling the main function\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfdd31e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba81c43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
